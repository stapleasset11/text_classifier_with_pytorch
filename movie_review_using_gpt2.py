# -*- coding: utf-8 -*-
"""Movie_Review_using_GPT2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/172-wfk4zP_YQFtVI-ZicQKjo5m9R7CVq

##1. Download Dataset.
"""

#Download Dataset
!wget -q -nc http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz

#Unzip
!tar -zxf /content/aclImdb_v1.tar.gz

"""##2. Install Dependencies."""

# Install transformers library.
!pip install -q git+https://github.com/huggingface/transformers.git
# Install helper functions.
!pip install -q git+https://github.com/gmihaila/ml_things.git

"""##3. Import dependencies."""

import io
import os
import torch
from tqdm import tqdm
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import classification_report, accuracy_score
from ml_things import plot_dict, plot_confusion_matrix, fix_text
from transformers import(set_seed,
                         TrainingArguments,
                         Trainer,
                         GPT2Config,
                         GPT2Tokenizer,
                         AdamW,
                         get_linear_schedule_with_warmup,
                         GPT2ForSequenceClassification)

#Set reproducibility seed
set_seed(124)

#Set Epochs
epochs = 5

#Set Batch size
batch_size = 32

#Set maximum text sequence
max_length = 60

#Setup device agnostic code
device = "cuda" if torch.cuda.is_available() else "cpu"

#Set the pretrained model to be used
model_name = 'gpt2'

#Create a dictionary of labels and their ids to convert string labels to number ids
label_ids = {'neg':0,'pos':1}

#Set number of labels
number_labels = len(label_ids)

"""#4. Instantiate the Model."""

class MovieReviewModel(Dataset):
  def __init__(self,path,use_tokenizer):

    #Check if path exists.
    if not os.path.isdir(path):
      raise ValueError('Invalid "path" variable!, Needs to be a directory...')

    self.texts = []
    self.labels = []

    #Loop through the labels.
    for label in ['pos','neg']:
      sentiment_path = os.path.join(path,label)

      #Get all files from path
      file_names = os.listdir(sentiment_path)

      #Read through each file.
      for file_name in tqdm(file_names, desc=f'{label} files'):
        file_path = os.path.join(sentiment_path,file_name)

        #Read content.
        content = io.open(file_path, mode='r', encoding='utf-8').read()

        #Resolve any unicode issues and save content.
        content = fix_text(content)
        self.texts.append(content)
        self.labels.append(label)

    #The number of sample texts
    self.n_examples = len(self.labels)


    return


  def __len__(self):
    return self.n_examples

  def __getitem__(self, item) :
    return {'text':self.texts[item],
            'label':self.labels[item]}

"""##5. Instantiate GPT2."""

class Gpt2Classification(object):
  def __init__(self,use_tokenizer,labels_encoder,max_sequence_len=None):

    #Set tokenizer.
    self.use_tokenizer = use_tokenizer

    #Check max sequence length and label encoder in each class.
    self.max_sequence_len = use_tokenizer.model_max_length if max_sequence_len is None else max_sequence_len

    self.labels_encoder = labels_encoder

    return

  def __call__(self,sequences):

    # Get all texts from sequences list.
    texts = [sequence['text'] for sequence in sequences]
    # Get all labels from sequences list.
    labels = [sequence['label'] for sequence in sequences]
    # Encode all labels using label encoder.
    labels = [self.labels_encoder[label] for label in labels]
    # Call tokenizer on all texts to convert into tensors of numbers with
    # appropriate padding.
    inputs = self.use_tokenizer(text=texts, return_tensors="pt", padding=True, truncation=True,  max_length=self.max_sequence_len)
    # Update the inputs with the associated encoded labels as tensor.
    inputs.update({'labels':torch.tensor(labels)})

    return inputs

"""##6.Train model on a single epoch first."""

def train(dataloader,optimizer_,scheduler_,device_):

  #Use global varible.
  global model

  predictions_labels = []
  true_labels = []

  #Test loss for this epoch
  train_loss = 0

  #Put model into train mode.
  model.train()

  # For each batch of training data...
  for batch in tqdm(dataloader, total=len(dataloader)):

    # Add original labels - use later for evaluation.
    true_labels += batch['labels'].numpy().flatten().tolist()

    # move batch to target device
    batch = {k:v.type(torch.long).to(device_) for k,v in batch.items()}

    #Zero grad
    model.zero_grad()

    #Perform a forward pass
    outputs = model(**batch)

    loss, logits = outputs[:2]

    train_loss += loss.item()

    loss.backward()

    torch.nn.utils.clip_grad_norm(model.parameters(),1.0)

    optimizer_.step()

    scheduler_.step()

    logits = logits.detach().cpu().numpy()

    predictions_labels += logits.argmax(axis=-1).flatten().tolist()

  avg_loss = train_loss / len(dataloader)

  return true_labels, predictions_labels, avg_loss

"""##7. Validate model on a single epoch first."""

def validation(dataloader,device_):

  global model

  predictions_labels = []
  true_labels = []

  test_loss = 0

  model.eval()

  for batch in tqdm(dataloader,total=len(dataloader)):
    true_labels += batch['labels'].numpy().flatten().tolist()

    batch = {k:v.type(torch.long).to(device_) for k,v in batch.items()}

    with torch.no_grad():
      outputs = model(**batch)

      loss, logits = outputs[:2]
      test_loss += loss.item()

      predict_content = logits.argmax(axis=-1).flatten().tolist()

      predictions_labels += predict_content

  avg_loss = test_loss/len(dataloader)

  return true_labels, predictions_labels, avg_loss

"""##8. Load model and Tokenizer."""

# Get model configuration.
print('Loading configuraiton...')
model_config = GPT2Config.from_pretrained(pretrained_model_name_or_path=model_name, num_labels=number_labels)

# Get model's tokenizer.
print('Loading tokenizer...')
tokenizer = GPT2Tokenizer.from_pretrained(pretrained_model_name_or_path=model_name)
# default to left padding
tokenizer.padding_side = "left"
# Define PAD Token = EOS Token = 50256
tokenizer.pad_token = tokenizer.eos_token


# Get the actual model.
print('Loading model...')
model = GPT2ForSequenceClassification.from_pretrained(pretrained_model_name_or_path=model_name, config=model_config)

# resize model embedding to match new tokenizer
model.resize_token_embeddings(len(tokenizer))

# fix model padding token id
model.config.pad_token_id = model.config.eos_token_id

# Load model to defined device.
model.to(device)
print('Model loaded to `%s`'%device)

"""##8. Create Dataset and Collator."""

# Create data collator to encode text and labels into numbers.
gpt2_classificaiton_collator = Gpt2Classification(use_tokenizer=tokenizer,
                                                          labels_encoder=label_ids,
                                                          max_sequence_len=max_length)

print('Dealing with Train...')
# Create pytorch dataset.
train_dataset = MovieReviewModel(path='/content/aclImdb/train',
                               use_tokenizer=tokenizer)
print('Created `train_dataset` with %d examples!'%len(train_dataset))

print()

# Move pytorch dataset into dataloader.
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=gpt2_classificaiton_collator)
print('Created `train_dataloader` with %d batches!'%len(train_dataloader))

print()

print('Dealing with Validation...')
# Create pytorch dataset.
test_dataset =  MovieReviewModel(path='/content/aclImdb/test',
                               use_tokenizer=tokenizer)
print('Created `valid_dataset` with %d examples!'%len(test_dataset))

# Move pytorch dataset into dataloader.
test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=gpt2_classificaiton_collator)
print('Created `eval_dataloader` with %d batches!'%len(test_dataloader))

"""##9. Perform Train step on the model.

"""

# Note: AdamW is a class from the huggingface library (as opposed to pytorch)
optimizer = torch.optim.AdamW(model.parameters(),
                  lr = 2e-5, # default is 5e-5, our notebook had 2e-5
                  eps = 1e-8 # default is 1e-8.
                  )

#Number of training steps...
total_steps = len(train_dataloader)* epochs

#Create the learning rate scheduler.
scheduler = get_linear_schedule_with_warmup(optimizer,
                                            num_warmup_steps = 0, # Default value in run_glue.py
                                            num_training_steps = total_steps)

# Store the average loss after each epoch so we can plot them.
all_loss = {'train_loss':[], 'test_loss':[]}
all_acc = {'train_acc':[], 'test_acc':[]}

# Loop through each epoch.
print('*****Epoch*****')
for epoch in tqdm(range(epochs)):
  print()
  print('Training on batches...')
  # Perform one full pass over the training set.
  train_labels, train_predict, train_loss = train(train_dataloader, optimizer, scheduler, device)
  train_acc = accuracy_score(train_labels, train_predict)

  # Get prediction form model on validation data.
  print('Validation on batches...')
  test_labels, test_predict, test_loss = validation(test_dataloader, device)
  test_acc = accuracy_score(test_labels, test_predict)

  # Print loss and accuracy values to see how training evolves.
  print("  train_loss: %.5f - val_loss: %.5f - train_acc: %.5f - valid_acc: %.5f"%(train_loss, test_loss, train_acc, test_acc))
  print()

 # Store the loss value for plotting the learning curve.
  all_loss['train_loss'].append(train_loss)
  all_loss['test_loss'].append(test_loss)
  all_acc['train_acc'].append(train_acc)
  all_acc['test_acc'].append(test_acc)

# Plot loss curves.
plot_dict(all_loss, use_xlabel='Epochs', use_ylabel='Value', use_linestyles=['-', '--'])

# Plot accuracy curves.
plot_dict(all_acc, use_xlabel='Epochs', use_ylabel='Value', use_linestyles=['-', '--'])

"""##10. Plot a confusion matrix to evaluate results."""

# Get prediction form model on validation data. This is where you should use.

true_labels, predictions_labels, avg_loss = validation(test_dataloader, device)

# Create the evaluation report.
evaluation_report = classification_report(true_labels, predictions_labels, labels=list(label_ids.values()), target_names=list(label_ids.keys()))
# Show the evaluation report.
print(evaluation_report)

# Plot confusion matrix.
plot_confusion_matrix(y_true=true_labels, y_pred=predictions_labels,
                      classes=list(label_ids.keys()), normalize=True,
                      magnify=0.1,
                      );

